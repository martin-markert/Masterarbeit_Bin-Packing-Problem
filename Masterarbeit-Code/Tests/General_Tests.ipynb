{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef105513",
   "metadata": {},
   "source": [
    "# Testing ```position_mask = packing_mask.all(1).all(1)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e804e1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: torch.Size([1, 2, 6, 2, 2])\n",
      "\n",
      "\n",
      "Flattened:\n",
      "tensor([[[[ True, False,  True,  True],\n",
      "          [False, False,  True, False],\n",
      "          [ True, False,  True,  True],\n",
      "          [ True, False,  True,  True],\n",
      "          [ True, False,  True,  True],\n",
      "          [ True, False,  True,  True]],\n",
      "\n",
      "         [[ True, False,  True,  True],\n",
      "          [ True, False,  True,  True],\n",
      "          [ True, False,  True,  True],\n",
      "          [ True, False,  True,  True],\n",
      "          [ True, False,  True,  True],\n",
      "          [ True, False,  True,  True]]]])\n",
      "\n",
      "Shape of x_flat: torch.Size([1, 2, 6, 4])\n",
      "\n",
      "\n",
      "x.all(1):\n",
      "tensor([[[ True, False,  True,  True],\n",
      "         [False, False,  True, False],\n",
      "         [ True, False,  True,  True],\n",
      "         [ True, False,  True,  True],\n",
      "         [ True, False,  True,  True],\n",
      "         [ True, False,  True,  True]]])\n",
      "\n",
      "Shape of x_all: torch.Size([1, 6, 4])\n",
      "\n",
      "\n",
      "x.all(1).all(1):\n",
      "tensor([[False, False,  True, False]])\n",
      "\n",
      "Shape of x_all_all: torch.Size([1, 4])\n",
      "\n",
      "\n",
      "x_flat.permuted\n",
      "tensor([[[[ True, False,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True,  True]],\n",
      "\n",
      "         [[False, False, False, False, False, False],\n",
      "          [False, False, False, False, False, False]],\n",
      "\n",
      "         [[ True,  True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True,  True]],\n",
      "\n",
      "         [[ True, False,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True,  True]]]])\n",
      "\n",
      "Shape of x_flat.permuted: torch.Size([1, 4, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "x = torch.tensor([[\n",
    "                    [\n",
    "                      [[ True,   False],\n",
    "                      [ True,   True]],\n",
    "\n",
    "                      [[ False,  False],\n",
    "                        [ True,   False]],\n",
    "\n",
    "                      [[ True,   False],\n",
    "                        [ True,   True]],\n",
    "\n",
    "                      [[ True,   False],\n",
    "                        [ True,   True]],\n",
    "\n",
    "                      [[ True,   False],\n",
    "                        [ True,   True]],\n",
    "\n",
    "                      [[ True,   False],\n",
    "                        [ True,   True]]\n",
    "                    ],\n",
    "\n",
    "                    [\n",
    "                      [[ True,   False],\n",
    "                        [ True,   True]],\n",
    "\n",
    "                      [[ True,   False],\n",
    "                        [ True,   True]],\n",
    "\n",
    "                      [[ True,   False],\n",
    "                        [ True,   True]],\n",
    "\n",
    "                      [[ True,   False],\n",
    "                        [ True,   True]],\n",
    "\n",
    "                      [[ True,   False],\n",
    "                        [ True,   True]],\n",
    "\n",
    "                        [[ True,   False],\n",
    "                        [ True,   True]]\n",
    "                      ]\n",
    "                  ]])\n",
    "\n",
    "print(f\"Shape of x: {x.shape}\")\n",
    "\n",
    "x_flat = x.flatten(3, 4)\n",
    "print(f\"\\n\\nFlattened:\\n{x_flat}\\n\")\n",
    "print(f\"Shape of x_flat: {x_flat.shape}\")\n",
    "\n",
    "x_all = x_flat.all(1)\n",
    "print(f\"\\n\\nx.all(1):\\n{x_all}\\n\")\n",
    "print(f\"Shape of x_all: {x_all.shape}\")\n",
    "\n",
    "\n",
    "x_all_all = x_flat.all(1).all(1)\n",
    "print(f\"\\n\\nx.all(1).all(1):\\n{x_all_all}\\n\")\n",
    "print(f\"Shape of x_all_all: {x_all_all.shape}\")\n",
    "\n",
    "x_premuted = x_flat.permute(0, 3, 1, 2)\n",
    "print(f\"\\n\\nx_flat.permuted\\n{x_premuted}\\n\")\n",
    "print(f\"Shape of x_flat.permuted: {x_premuted.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b850a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0349,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.1738,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.9293,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.3734,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.0000, 1.9312,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9693],\n",
       "         [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.0744,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0226,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.5546,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8044,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.0000, 1.7770,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9239],\n",
       "         [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.9228,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0069,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9721,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.5038,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.4835,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0996],\n",
       "         [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.0000, 0.4888,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.2332,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.0000, 0.6174,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6964,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.0956,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6625],\n",
       "         [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.0000, 1.7615,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.2095,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.7436,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.7455,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1554,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.9261],\n",
       "         [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.3755,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.2948,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.6809,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1467,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0973,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.7528]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def binary_encoder(x, binary_dim):\n",
    "    # x: size x 1\n",
    "    if binary_dim == 1:\n",
    "        x_encoding = x\n",
    "    else:\n",
    "        binary_list = []\n",
    "        divide = x\n",
    "        for i in range(binary_dim):\n",
    "            binary = divide % 2\n",
    "            binary_list.insert(0,binary)\n",
    "            divide = torch.div(divide,2,rounding_mode='trunc')\n",
    "\n",
    "        x_encoding = torch.stack(binary_list,-1).flatten(-2,-1)\n",
    "    return x_encoding\n",
    "\n",
    "x = torch.tensor(\n",
    "    [[[-1.9651,  6.1738, -1.0707, 2.3734, -2.0688,  0.9693],\n",
    "      [-0.9256,  5.0226, -0.4454, 2.8044, -2.2230,  0.9239],\n",
    "      [-0.0772,  5.0069,  0.9721, 3.5038, -1.5165,  1.0996],\n",
    "      [-3.5112,  2.2332, -3.3826, 0.6964, -0.9044,  1.6625],\n",
    "      [-2.2385,  2.2095, -1.2564, 1.7455,  0.1554,  1.9261],\n",
    "      [-1.6245,  2.2948, -1.3191, 1.1467,  0.0973,  1.7528]]],\n",
    "    dtype=torch.float32\n",
    ")\n",
    "binary_encoder(x, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c4b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
